# MCP Broker

An MCP server that acts as a **tool-routing broker** â€” tool providers connect outbound via WebSocket and publish tools, while standard MCP clients consume them transparently through the broker.

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  HTTP (MCP)  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   WebSocket    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MCP Client  â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  MCP Broker          â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Tool Provider   â”‚
â”‚  (any)       â”‚  :3098/mcp   â”‚                      â”‚    :3099       â”‚  (broker client) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  - tool registry     â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚  - call routing      â”‚   WebSocket    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  - namespacing       â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Tool Provider   â”‚
                              â”‚                      â”‚                â”‚  (broker client) â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Normal MCP clients** connect via Streamable HTTP (`http://localhost:3098/mcp`) and see a standard MCP server.
**Broker clients** (tool providers) connect outbound via WebSocket (`ws://localhost:3099`), register tools, and handle calls routed from MCP clients.

## Quick Start

```bash
cd mcp-broker
npm install
npm run broker
# Server listening:  HTTP MCP on :3098  |  WebSocket on :3099
```

## Examples

Examples are organized into folders by use case:

```
examples/
  list-tools.js          â† General utility: list all connected clients & tools
  hello-world/           â† Basic greet/add demo with orchestrators
  simple-service/        â† Minimal long-running service (ping, chat, exit)
  ai-invoke/             â† AI code generation via chat proxy
  ollama/                â† Ollama broker-client (generate tool)
  chrome-ext-demo/       â† Chrome extension with clock, properties tab, auto-announcer
```

## Full Demo (all-in-one)

Runs the server, a broker-client, and an MCP client in one command:

```bash
npm run demo
```

## Step-by-Step Demo (single command)

Runs the same 3-terminal flow (server â†’ broker-client â†’ MCP client) orchestrated as one process:

```bash
npm run demo:stepwise
```

This starts the server, waits for it, starts the broker-client, waits for registration, then runs the MCP client â€” all with automatic cleanup.

## Serve Mode

Starts the server + sample broker-client together, staying alive for interactive use:

```bash
npm run example:serve
# Both running. Now use another command or the Chrome extension.
```

Useful when you want the server running for:
- The Chrome extension demo (see below)
- Manual `npm run example:client` testing
- The auto-announcer (`npm run example:auto-announce`)

## Step-by-Step Demo (manual, 3 terminals)

### 1. Start the server

```bash
npm run broker
# [broker] WebSocket server listening on port 3099
# [broker] MCP HTTP server listening on http://localhost:3098/mcp
```

### 2. Start a broker-client (publishes tools)

In a second terminal:

```bash
npm run example:broker-client
# Broker client "hello-world" connected â€” publishing greet, add
```

### 3. Use an MCP client to call those tools

In a third terminal:

```bash
npm run example:client
# Connects to http://localhost:3098/mcp
# Lists tools: hello-world__greet, hello-world__add, list_broker_clients
# Calls greet and add â€” results printed
```

## Chrome Extension Demo

A full browser demo: a Chrome extension with a PST clock page that auto-injects a broker-client, speaks the time via kokoro-tts, polls the MCP server for live tool status, and publishes tools callable by any MCP client.

### Features

- **Auto-inject**: Broker client connects on page load â€” no manual popup click needed
- **Streamable HTTP MCP browser client**: The clock page polls `http://localhost:3098/mcp` using the rewritten `McpBrowserClient` (fetch POST, stateless)
- **Live tools panel**: Clickable tool buttons with inline results (5s polling)
- **Ollama inference panel**: Prompt input + response textarea â€” calls LLM through MCP
- **Server health indicators**: Green/red dots for MCP server and broker-client connection
- **Exponential backoff**: WebSocket reconnect starts at 2s, doubles to 30s max
- **Tab visibility handling**: Reconnects immediately when the tab becomes visible
- **Duplicate tab prevention**: Popup focuses existing clock tab instead of opening a new one
- **Two published tools**: `clickAnnounce` (clicks the button) and `getTime` (reads the clock)
- **Properties tab**: Iterative AI property resolution â€” add named properties via multi-turn AI conversation
- **Property broker-client**: `property-rc.js` publishes `addProperty`, `getProperty`, `listProperties` tools
- **AI conversation log**: Real-time visualization of the iterative gather â†’ generate â†’ eval cycle
- **Refresh button**: Re-poll tools on demand from clock page and popup

### Quick Start (single command)

```bash
npm run example:serve:chrome
```

Starts the MCP broker server + auto-announcer in one process, then prints
instructions for loading the Chrome extension. Once the clock page connects,
the auto-announcer calls `clickAnnounce` every 15s.

### Manual Setup

1. Start the server: `npm run broker`
2. Open `chrome://extensions`, enable **Developer mode**
3. Click **Load unpacked**, select `examples/chrome-ext-demo/`
4. Click the extension icon â†’ **Open Clock Page**
5. The page auto-injects the broker-client (RC status turns green)
6. The tools panel at the bottom shows live MCP tools
7. Server status indicator (top-left) shows online/offline

### Files

| File | Role |
|---|---|
| `manifest.json` | MV3 manifest, `tabs` permission, CSP for localhost |
| `clock.html` | Clock UI with tabbed layout (Clock / Properties), server status, tools panel, ollama panel |
| `clock.js` | Clock logic, auto-inject (both RCs), tab switching, MCP polling, tool buttons, property form |
| `inject.js` | Broker client: publishes `clickAnnounce` + `getTime` via WS :3099 |
| `property-rc.js` | Property broker-client: publishes `addProperty` + `getProperty` + `listProperties` via WS :3099 |
| `mcp-browser-client.js` | Streamable HTTP MCP client for the browser (fetch POST, SSE parsing) |
| `popup.html` | Popup with health panel, clickable tool buttons, refresh |
| `popup.js` | Health checks, tool loading/calling, tab management |
| `background.js` | Service worker with server health API |
| `auto-announce.js` | Node.js MCP client that calls `clickAnnounce` every 15s |
| `click-announce.js` | One-shot MCP client: lists tools + calls clickAnnounce |
| `serve-chrome.js` | Orchestrator: starts server + auto-announcer in one command |

### Auto-Announcer

A Node.js MCP client that calls `clickAnnounce` every 15 seconds:

```bash
# Requires: server running (npm run broker) + Chrome extension injected
npm run example:auto-announce
# Connects to http://localhost:3098/mcp
# Calls clock-page__clickAnnounce every 15s
# Clock page speaks the current PST time via kokoro-tts
```

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   HTTP MCP    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   WebSocket    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ auto-announce â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  broker-client  â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  inject.js          â”‚
â”‚ (MCP client)  â”‚  :3098/mcp   â”‚  server (broker) â”‚    :3099       â”‚  (clock tools RC)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                 â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                 â”‚   WebSocket    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   HTTP MCP    â”‚                 â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  property-rc.js     â”‚
â”‚ clock.js      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                 â”‚                â”‚  (property agent RC) â”‚
â”‚ (MCP browser  â”‚  :3098/mcp   â”‚                 â”‚                â”‚  â†’ chat_request     â”‚
â”‚  client)      â”‚              â”‚                 â”‚                â”‚  â†’ Ollama MCP :3042 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                 â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                 â”‚   WebSocket    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚                 â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  ollama-rc.js       â”‚
                                â”‚                 â”‚    :3099       â”‚  (Ollama RC)        â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  â†’ Ollama :11434    â”‚
                                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The clock page acts as **both** an MCP client (via `McpBrowserClient`) and hosts two broker-clients (`inject.js` for clock tools, `property-rc.js` for AI property resolution). When a user types a prompt, the browser calls `ollama__generate` through the MCP broker, which routes the call to the Ollama broker-client.

### Properties Tab â€” Iterative AI Property Resolution

The Properties tab demonstrates a **customer-service-style AI interaction** pattern. Instead of generating code from a single prompt, the AI asks what information it needs, gathers each requirement from the live page, then generates code with full context.

**How `addProperty` works:**

1. User provides a **name** (e.g. `buttonCount`) and a **prompt** (e.g. "count all buttons on the page")
2. The property-rc sends the prompt to AI via `chat_request` â†’ broker â†’ Ollama MCP
3. AI responds with a **numbered checklist** of questions about the page
4. For each checklist item, the AI suggests a **JS expression** to eval in the browser
5. The expression is eval'd, and the result is fed back to the AI
6. Once all data is gathered, the AI generates a **final expression** with full context
7. The expression is eval'd and stored as a named property (re-evaluable via `getProperty`)

The entire conversation is rendered live in the **AI Conversation Log** panel â€” every requirement gathered, every expression evaluated, every result captured.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Properties Tab UI                                                         â”‚
â”‚                                                                            â”‚
â”‚  â”Œâ”€ Tool Select â”€â”  â”Œâ”€ Name â”€â”€â”€â”€â”€â”€â”  â”Œâ”€ Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ property-agent â”‚  â”‚ buttonCount â”‚  â”‚ count all buttons on the page   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                            â”‚
â”‚  AI Conversation Log:                                                      â”‚
â”‚  â–¶ START  Adding property "buttonCount" â€” "count all buttons"              â”‚
â”‚  ðŸ” ASKING AI  What info do you need?                                      â”‚
â”‚  ðŸ“‹ CHECKLIST  1. What framework is the page using?                        â”‚
â”‚                2. Are buttons in shadow DOM?                                â”‚
â”‚  ðŸ“¡ GATHER #1  What framework is the page using?                           â”‚
â”‚  ðŸ§ª EVAL #1    typeof React !== 'undefined' ? 'React' : 'vanilla'         â”‚
â”‚  âœ… DATA #1    vanilla                                                     â”‚
â”‚  ðŸ“¡ GATHER #2  Are buttons in shadow DOM?                                  â”‚
â”‚  ðŸ§ª EVAL #2    document.querySelector('*').shadowRoot !== null             â”‚
â”‚  âœ… DATA #2    false                                                       â”‚
â”‚  ðŸ¤– GENERATING CODE  All data gathered, requesting final expression        â”‚
â”‚  ðŸ’¡ CODE  document.querySelectorAll('button').length                       â”‚
â”‚  ðŸŽ‰ DONE  buttonCount = 3                                                 â”‚
â”‚                                                                            â”‚
â”‚  Resolved Properties:                                                      â”‚
â”‚  buttonCount = 3  ("count all buttons on the page")                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why this pattern matters:**
- The AI doesn't guess â€” it **inspects the actual page** before generating code
- Each requirement is independently verified with real data
- The conversation log provides full transparency into the AI's reasoning
- Properties are re-evaluable: `getProperty` re-runs the generated code for fresh values
- Demonstrates how broker-clients can use `chat_request` for multi-turn AI conversations

## npm Scripts

| Script | Command | Description |
|---|---|---|
| `npm run broker` | `node server.js` | Start the broker server (long-running) |
| `npm run ls` | `node examples/list-tools.js` | List connected broker-clients and available tools (exits) |
| `npm run example:broker-client` | `node examples/hello-world/broker-client.js` | Start a sample broker-client (long-running) |
| `npm run example:client` | `node examples/hello-world/mcp-client.js` | Run an MCP client against the server (exits) |
| `npm run demo` | `node examples/hello-world/demo.js` | All-in-one demo â€” server + RC + client (exits) |
| `npm run demo:stepwise` | `node examples/hello-world/demo-stepwise.js` | Step-by-step demo orchestrated in one process (exits) |
| `npm run example:serve` | `node examples/hello-world/serve.js` | Server + sample RC together (long-running) |
| `npm run example:serve:chrome` | `node examples/chrome-ext-demo/serve-chrome.js` | Server + auto-announcer for Chrome ext demo (long-running) |
| `npm run example:auto-announce` | `node examples/chrome-ext-demo/auto-announce.js` | Call `clickAnnounce` every 15s via MCP (long-running) |
| `npm run example:click` | `node examples/chrome-ext-demo/click-announce.js` | One-shot: list tools + call clickAnnounce (exits) |
| `npm run example:ollama` | `node examples/ollama/ollama-rc.js` | Ollama broker-client â€” publishes `generate` tool (long-running) |
| `npm run example:ai-invoke` | `node examples/ai-invoke/ai-invoke-rc.js` | AI-invoke broker-client â€” uses `chat()` to generate + eval code (long-running) |
| `npm run example:ai-caller` | `node examples/ai-invoke/ai-caller.js` | MCP client that calls the `invoke` tool with natural language (exits) |
| `npm run example:service` | `node examples/simple-service/simple-service.js` | Minimal long-running service with ping, chat, exit tools |

## Ollama Integration

The Ollama broker-client connects to the MCP broker and publishes a `generate` tool that wraps the local Ollama API. The Chrome extension clock page includes a prompt/response panel that calls this tool through the MCP broker â€” enabling LLM inference directly from the browser.

### Setup

1. Install and run Ollama: `ollama serve`
2. Pull a model: `ollama pull qwen2.5:3b`
3. Start the MCP server: `npm run broker`
4. Start the Ollama broker-client: `npm run example:ollama`
5. Load the Chrome extension and open the clock page
6. Type a prompt in the **Ollama Inference** panel and hit **Send**

### How It Works

```
Browser (clock.js)           MCP Broker (:3098)        ollama-rc.js            Ollama (:11434)
      â”‚                            â”‚                        â”‚                       â”‚
      â”‚  POST /mcp                 â”‚                        â”‚                       â”‚
      â”‚  tools/call                â”‚                        â”‚                       â”‚
      â”‚  ollama__generate          â”‚                        â”‚                       â”‚
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                        â”‚                       â”‚
      â”‚                            â”‚  WS: tool_call         â”‚                       â”‚
      â”‚                            â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                       â”‚
      â”‚                            â”‚                        â”‚  POST /api/generate   â”‚
      â”‚                            â”‚                        â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
      â”‚                            â”‚                        â”‚                       â”‚
      â”‚                            â”‚                        â”‚  â—„â”€ JSON response â”€â”€  â”‚
      â”‚                            â”‚  â—„â”€â”€ tool_result â”€â”€â”€â”€  â”‚                       â”‚
      â”‚  â—„â”€â”€ SSE response â”€â”€â”€â”€â”€â”€â”€ â”‚                        â”‚                       â”‚
      â”‚                            â”‚                        â”‚                       â”‚
```

### Configuration

| Environment Variable | Default | Description |
|---|---|---|
| `OLLAMA_URL` | `http://localhost:11434` | Ollama API base URL |
| `OLLAMA_MODEL` | `qwen2.5:3b` | Default model for generate calls |
| `BROKER_WS_URL` | `ws://localhost:3099` | MCP broker WebSocket URL |

## VS Code MCP Configuration

Add to your `.vscode/mcp.json`:

```json
{
  "servers": {
    "mcp-broker": {
      "type": "streamable-http",
      "url": "http://localhost:3098/mcp"
    }
  }
}
```

## Chat Proxy (AI Access for Broker-Clients)

Every connected broker-client has access to AI inference via `rc.chat()`. The request travels through the broker, which proxies to the Ollama MCP server â€” so broker-clients never need to know about Ollama directly.

### Flow

```
Broker-Client              Broker (:3099)         Ollama MCP (:3042)
      â”‚                            â”‚                             â”‚
      â”‚  WS: chat_request          â”‚                             â”‚
      â”‚  {model, messages}         â”‚                             â”‚
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                             â”‚
      â”‚                            â”‚  MCP tools/call             â”‚
      â”‚                            â”‚  request({prompt, model})   â”‚
      â”‚                            â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
      â”‚                            â”‚                             â”‚  â†’ Ollama API
      â”‚                            â”‚  â—„â”€â”€ tool result â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
      â”‚  â—„â”€â”€ WS: chat_response â”€â”€  â”‚                             â”‚
      â”‚  {message: {role, content}} â”‚                             â”‚
```

### Usage

```javascript
const response = await rc.chat({
  model: 'qwen2.5:3b',
  messages: [
    { role: 'system', content: 'You write JavaScript code.' },
    { role: 'user', content: 'Return code that counts all buttons' },
  ],
});
console.log(response.message.content);
```

### AI-Invoke Example

A broker-client that uses `chat()` to dynamically generate and execute code:

```bash
# Terminal 1: Start Ollama MCP server (port 3042)
# Terminal 2:
npm run broker
# Terminal 3:
npm run example:ai-invoke
# Terminal 4:
npm run example:ai-caller
```

The caller sends natural language instructions, the ai-invoke RC asks the AI to generate code via `chat()`, evals it, and returns the result.

## SDK Usage

```javascript
import { BrokerClient } from './sdk.js';

const rc = new BrokerClient('my-agent', { url: 'ws://localhost:3099' });

rc.addTool({
  name: 'screenshot',
  description: 'Take a screenshot of the current page',
  inputSchema: { type: 'object', properties: {} },
  handler: async () => {
    // Your implementation here
    return 'screenshot taken';
  },
});

await rc.connect();

// Chat is available immediately after connect
const response = await rc.chat({
  model: 'qwen2.5:3b',
  messages: [{ role: 'user', content: 'Hello' }],
});
console.log(response.message.content);
```

## Tool Namespacing

Tools are automatically namespaced by client ID to prevent collisions:

| Broker-Client ID | Tool Name | MCP Tool Name |
|---|---|---|
| `browser1` | `screenshot` | `browser1__screenshot` |
| `game1` | `getState` | `game1__getState` |

## Built-in Tools

| Tool | Description |
|---|---|
| `list_broker_clients` | Lists all connected broker-clients and their tools |

## Protocol

WebSocket messages between server and broker-clients:

| Direction | Type | Fields |
|---|---|---|
| client â†’ server | `register` | `clientId`, `tools` |
| server â†’ client | `registered` | `clientId` |
| client â†’ server | `unregister` | â€” |
| server â†’ client | `tool_call` | `callId`, `tool`, `arguments` |
| client â†’ server | `tool_result` | `callId`, `content`, `isError` |
| client â†’ server | `chat_request` | `requestId`, `payload` (Ollama chat format) |
| server â†’ client | `chat_response` | `requestId`, `payload` (Ollama chat response) |
| server â†’ client | `chat_error` | `requestId`, `error` |

## Dashboard

The broker includes a built-in web dashboard at `http://localhost:3098/` with:

- **Stats bar** â€” Uptime, connected clients, total tools, call/chat counts
- **Tool Explorer** â€” Hierarchical client â†’ tool tree with expand/collapse
- **Interactive Tool Panel** â€” Select any tool to see an auto-generated form from its `inputSchema`, fill in parameters, and click **Run Tool** to invoke it via `POST /api/call-tool`
- **Activity Log** â€” Real-time SSE feed of connections, tool calls, and chat requests
- **Live indicator** â€” SSE connection status (green = connected)

### Dashboard API

| Endpoint | Method | Description |
|---|---|---|
| `/` | GET | Dashboard HTML |
| `/api/status` | GET | Server status snapshot (clients, tools, stats) |
| `/api/activity` | GET | Recent activity entries |
| `/api/events` | GET | SSE stream (state + activity events) |
| `/api/call-tool` | POST | Invoke a tool: `{ clientId, tool, arguments }` â†’ `{ content, isError, duration }` |

## Docker

Run the broker as a container:

```bash
# Build and run with docker-compose
docker compose up -d

# Or build manually
docker build -t mcp-broker .
docker run -p 3098:3098 -p 3099:3099 mcp-broker
```

## Configuration

| Env Variable | Default | Description |
|---|---|---|
| `BROKER_WS_PORT` | `3099` | WebSocket port for broker-clients |
| `MCP_HTTP_PORT` | `3098` | HTTP port for MCP clients |
| `OLLAMA_MCP_URL` | `http://localhost:3042/mcp` | Ollama MCP server URL for chat proxy |
